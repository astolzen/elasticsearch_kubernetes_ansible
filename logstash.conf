# Logstash Pipeline Configuration
# Processes logs from Kafka topics and sends to Elasticsearch

input {
  # Kafka input for journals topic
  kafka {
    bootstrap_servers => "<< Kafka broker IP:port >>"
    topics => ["journals"]
    group_id => "logstash-journals"
    consumer_threads => 1
    decorate_events => true
    codec => json
    tags => ["journals"]
  }

  # Kafka input for pihole topic
  kafka {
    bootstrap_servers => "<< Kafka broker IP:port >>"
    topics => ["pihole"]
    group_id => "logstash-pihole"
    consumer_threads => 1
    decorate_events => true
    codec => json
    tags => ["pihole"]
  }
}

filter {
  # Add pipeline identifier based on tag
  if "journals" in [tags] {
    mutate {
      add_field => { "logstash_pipeline" => "journals" }
    }
  }

  if "pihole" in [tags] {
    mutate {
      add_field => { "logstash_pipeline" => "pihole" }
    }

    # Parse DNS query patterns for pihole logs
    # Pattern: query[A] or query[AAAA] domain from IP
    grok {
      match => {
        "message" => [
          "query\[(?:A|AAAA)\]\s+(?<dns_queried_system>\S+)\s+from\s+(?<dns_query_from>%{IP})"
        ]
      }
      tag_on_failure => []
    }

    # Parse gravity blocked patterns
    # Pattern: gravity blocked domain is response
    grok {
      match => {
        "message" => [
          "gravity blocked %{NOTSPACE:dns_queried_system} is %{NOTSPACE:dns_query_blocked_response}"
        ]
      }
      tag_on_failure => []
    }

    # Parse DNS resolution patterns
    # Pattern: reply/cached/cached-stale domain is IP
    grok {
      match => {
        "message" => [
          "(?:reply|cached|cached-stale)\s+(?<dns_queried_system>\S+)\s+is\s+(?<dns_queried_system_ip>%{IP})"
        ]
      }
      tag_on_failure => []
    }
  }

  # Ensure @timestamp field exists
  if ![@timestamp] {
    mutate {
      add_field => { "@timestamp" => "%{[@metadata][kafka][timestamp]}" }
    }
  }

  # Remove unnecessary metadata fields
  mutate {
    remove_field => ["@metadata"]
  }
}

output {
  # Output journals to journals-* index
  if "journals" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "journals-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  # Output pihole to pihole-* index (will use geoip pipeline)
  if "pihole" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "pihole-%{+YYYY.MM.dd}"
      document_type => "_doc"
      pipeline => "geoip-pipeline"
    }
  }

  # Debug output (optional - comment out in production)
  # stdout {
  #   codec => rubydebug
  # }
}


